{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from termcolor import colored\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minst_df():\n",
    "    #load data\n",
    "    (train_validation_ds,test_ds),ds_info = tfds.load(name = \"mnist\",\n",
    "                                                      split = [\"train\",\"test\"],\n",
    "                                                      shuffle_files=True,\n",
    "                                                      as_supervised=True, \n",
    "                                                      with_info = True)\n",
    "    \n",
    "    #get number of train/validation and test data set\n",
    "    n_train_validation_ds = ds_info.splits[\"train\"].num_examples\n",
    "    n_test_ds = ds_info.splits[\"test\"].num_examples\n",
    "\n",
    "    #shuffle before splitting into train and valid set\n",
    "    train_validation_ds = train_validation_ds.shuffle(1000)\n",
    "\n",
    "    #split into train and validation dataset\n",
    "    train_ratio = 0.8\n",
    "    n_train = int(train_ratio*n_train_validation_ds)\n",
    "    n_valid = n_train_validation_ds - n_train\n",
    "\n",
    "    train_ds = train_validation_ds.take(n_train) #train: take first 80 percents of data\n",
    "    validation_ds = train_validation_ds.skip(n_train).take(n_valid)\n",
    "\n",
    "    print(\"train_ds num:\", len(train_ds))\n",
    "    print(\"validation_ds num:\", len(validation_ds))\n",
    "    print(\"test_ds num:\", len(test_ds))\n",
    "    \n",
    "    return (train_ds,validation_ds,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(TRAIN_BATCH_SIZE, TEST_BATCH_SIZE):\n",
    "    global train_ds,validation_ds,test_ds\n",
    "    \n",
    "    #standardize the input data and change datatype\n",
    "    def stnd(images, labels):\n",
    "        images = tf.cast(images, tf.float32)/255.\n",
    "        return [images, labels]\n",
    "        \n",
    "    train_ds = train_ds.map(stnd).shuffle(1000).batch(TRAIN_BATCH_SIZE)\n",
    "    validation_ds = validation_ds.map(stnd).batch(TEST_BATCH_SIZE)\n",
    "    test_ds = test_ds.map(stnd).batch(TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "class MINIST_Classifier(Model): #inherit tensorflow model\n",
    "    def __init__(self):\n",
    "        super(MINIST_Classifier,self).__init__()\n",
    "        \n",
    "        #define ingredients\n",
    "        self.flatten = Flatten()\n",
    "        self.layer_1 = Dense(units = 64, activation = \"relu\")\n",
    "        self.layer_2 = Dense(units = 10, activation = \"softmax\")\n",
    "    \n",
    "    def call(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x\n",
    "        \n",
    "def load_metrics():\n",
    "    global train_loss, train_acc\n",
    "    global validation_loss, validation_acc\n",
    "    global test_loss, test_acc\n",
    "    \n",
    "    train_loss, validation_loss, test_loss = Mean(), Mean(), Mean()\n",
    "    train_acc, validation_acc, test_acc = (SparseCategoricalAccuracy(),\n",
    "                                           SparseCategoricalAccuracy(), \n",
    "                                           SparseCategoricalAccuracy())\n",
    "    \n",
    "@tf.function\n",
    "def trainer():\n",
    "    global train_ds, model, loss_object, optimizer\n",
    "    global train_acc, train_loss\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images)\n",
    "            loss = loss_object(labels, predictions)\n",
    "            \n",
    "        gradients = tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "        train_acc(labels, predictions)\n",
    "        \n",
    "@tf.function\n",
    "def validation():\n",
    "    global validation_ds, model, loss_object\n",
    "    global validation_acc, validation_loss\n",
    "    \n",
    "    for images, labels in validation_ds:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "\n",
    "        validation_loss(loss)\n",
    "        validation_acc(labels, predictions)\n",
    "        \n",
    "        \n",
    "@tf.function\n",
    "def test():\n",
    "    global test_ds, model, loss_object\n",
    "    global test_acc, test_loss\n",
    "    \n",
    "    for images, labels in test_ds:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "\n",
    "        test_loss(loss)\n",
    "        test_acc(labels, predictions)\n",
    "        \n",
    "        \n",
    "def reporter():\n",
    "    global epoch\n",
    "    global train_acc, train_loss\n",
    "    global validation_acc, validation_loss\n",
    "    \n",
    "    print(colored(\"EPOCH {}\".format(epoch+1), \"white\",\"on_cyan\"))\n",
    "    template = \"Train Loss:{:.4f}\\t Train Acc:{:.2f}%\\nValid Loss:{:.4f}\\t Valid Acc:{:.2f}%\"\n",
    "    print(template.format(train_loss.result(),\n",
    "                          train_acc.result()*100,\n",
    "                          validation_loss.result(),\n",
    "                          validation_acc.result()*100))\n",
    "    \n",
    "    train_acc.reset_states()\n",
    "    train_loss.reset_states()\n",
    "    validation_loss.reset_states()\n",
    "    validation_acc.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds num: 48000\n",
      "validation_ds num: 12000\n",
      "test_ds num: 10000\n",
      "\u001b[46m\u001b[37mEPOCH 1\u001b[0m\n",
      "Train Loss:1.8795\t Train Acc:45.05%\n",
      "Valid Loss:1.4440\t Valid Acc:68.63%\n",
      "\u001b[46m\u001b[37mEPOCH 2\u001b[0m\n",
      "Train Loss:1.1655\t Train Acc:75.26%\n",
      "Valid Loss:0.9581\t Valid Acc:79.76%\n",
      "\u001b[46m\u001b[37mEPOCH 3\u001b[0m\n",
      "Train Loss:0.8346\t Train Acc:81.49%\n",
      "Valid Loss:0.7415\t Valid Acc:83.18%\n",
      "\u001b[46m\u001b[37mEPOCH 4\u001b[0m\n",
      "Train Loss:0.6771\t Train Acc:83.94%\n",
      "Valid Loss:0.6277\t Valid Acc:85.03%\n",
      "\u001b[46m\u001b[37mEPOCH 5\u001b[0m\n",
      "Train Loss:0.5881\t Train Acc:85.47%\n",
      "Valid Loss:0.5610\t Valid Acc:86.05%\n",
      "\u001b[46m\u001b[37mEPOCH 6\u001b[0m\n",
      "Train Loss:0.5299\t Train Acc:86.61%\n",
      "Valid Loss:0.5136\t Valid Acc:86.93%\n",
      "\u001b[46m\u001b[37mEPOCH 7\u001b[0m\n",
      "Train Loss:0.4897\t Train Acc:87.27%\n",
      "Valid Loss:0.4775\t Valid Acc:87.70%\n",
      "\u001b[46m\u001b[37mEPOCH 8\u001b[0m\n",
      "Train Loss:0.4612\t Train Acc:87.78%\n",
      "Valid Loss:0.4531\t Valid Acc:88.05%\n",
      "\u001b[46m\u001b[37mEPOCH 9\u001b[0m\n",
      "Train Loss:0.4382\t Train Acc:88.29%\n",
      "Valid Loss:0.4342\t Valid Acc:88.47%\n",
      "\u001b[46m\u001b[37mEPOCH 10\u001b[0m\n",
      "Train Loss:0.4201\t Train Acc:88.72%\n",
      "Valid Loss:0.4162\t Valid Acc:88.94%\n",
      "\u001b[46m\u001b[37mEPOCH 11\u001b[0m\n",
      "Train Loss:0.4052\t Train Acc:88.97%\n",
      "Valid Loss:0.4020\t Valid Acc:89.30%\n",
      "\u001b[46m\u001b[37mEPOCH 12\u001b[0m\n",
      "Train Loss:0.3916\t Train Acc:89.33%\n",
      "Valid Loss:0.3909\t Valid Acc:89.52%\n",
      "\u001b[46m\u001b[37mEPOCH 13\u001b[0m\n",
      "Train Loss:0.3819\t Train Acc:89.50%\n",
      "Valid Loss:0.3825\t Valid Acc:89.78%\n",
      "\u001b[46m\u001b[37mEPOCH 14\u001b[0m\n",
      "Train Loss:0.3720\t Train Acc:89.73%\n",
      "Valid Loss:0.3731\t Valid Acc:89.86%\n",
      "\u001b[46m\u001b[37mEPOCH 15\u001b[0m\n",
      "Train Loss:0.3635\t Train Acc:89.97%\n",
      "Valid Loss:0.3663\t Valid Acc:90.09%\n",
      "\u001b[46m\u001b[37mEPOCH 16\u001b[0m\n",
      "Train Loss:0.3568\t Train Acc:90.10%\n",
      "Valid Loss:0.3608\t Valid Acc:90.16%\n",
      "\u001b[46m\u001b[37mEPOCH 17\u001b[0m\n",
      "Train Loss:0.3498\t Train Acc:90.30%\n",
      "Valid Loss:0.3512\t Valid Acc:90.48%\n",
      "\u001b[46m\u001b[37mEPOCH 18\u001b[0m\n",
      "Train Loss:0.3443\t Train Acc:90.42%\n",
      "Valid Loss:0.3492\t Valid Acc:90.57%\n",
      "\u001b[46m\u001b[37mEPOCH 19\u001b[0m\n",
      "Train Loss:0.3384\t Train Acc:90.53%\n",
      "Valid Loss:0.3432\t Valid Acc:90.72%\n",
      "\u001b[46m\u001b[37mEPOCH 20\u001b[0m\n",
      "Train Loss:0.3335\t Train Acc:90.65%\n",
      "Valid Loss:0.3373\t Valid Acc:90.81%\n",
      "\u001b[46m\u001b[37mEPOCH 21\u001b[0m\n",
      "Train Loss:0.3293\t Train Acc:90.76%\n",
      "Valid Loss:0.3341\t Valid Acc:90.90%\n",
      "\u001b[46m\u001b[37mEPOCH 22\u001b[0m\n",
      "Train Loss:0.3244\t Train Acc:90.88%\n",
      "Valid Loss:0.3334\t Valid Acc:90.92%\n",
      "\u001b[46m\u001b[37mEPOCH 23\u001b[0m\n",
      "Train Loss:0.3204\t Train Acc:91.00%\n",
      "Valid Loss:0.3270\t Valid Acc:91.03%\n",
      "\u001b[46m\u001b[37mEPOCH 24\u001b[0m\n",
      "Train Loss:0.3159\t Train Acc:91.10%\n",
      "Valid Loss:0.3264\t Valid Acc:91.04%\n",
      "\u001b[46m\u001b[37mEPOCH 25\u001b[0m\n",
      "Train Loss:0.3131\t Train Acc:91.15%\n",
      "Valid Loss:0.3224\t Valid Acc:91.19%\n",
      "\u001b[46m\u001b[37mEPOCH 26\u001b[0m\n",
      "Train Loss:0.3088\t Train Acc:91.31%\n",
      "Valid Loss:0.3169\t Valid Acc:91.38%\n",
      "\u001b[46m\u001b[37mEPOCH 27\u001b[0m\n",
      "Train Loss:0.3058\t Train Acc:91.38%\n",
      "Valid Loss:0.3162\t Valid Acc:91.39%\n",
      "\u001b[46m\u001b[37mEPOCH 28\u001b[0m\n",
      "Train Loss:0.3031\t Train Acc:91.47%\n",
      "Valid Loss:0.3119\t Valid Acc:91.50%\n",
      "\u001b[46m\u001b[37mEPOCH 29\u001b[0m\n",
      "Train Loss:0.2996\t Train Acc:91.59%\n",
      "Valid Loss:0.3091\t Valid Acc:91.45%\n",
      "\u001b[46m\u001b[37mEPOCH 30\u001b[0m\n",
      "Train Loss:0.2963\t Train Acc:91.69%\n",
      "Valid Loss:0.3048\t Valid Acc:91.58%\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 30\n",
    "LR = 0.001\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "train_ds,validation_ds,test_ds = get_minst_df()\n",
    "standardization(32,32)\n",
    "\n",
    "load_metrics()\n",
    "\n",
    "model = MINIST_Classifier()\n",
    "loss_object = SparseCategoricalCrossentropy()\n",
    "optimizer = SGD(learning_rate=LR)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    trainer()\n",
    "    validation()\n",
    "    reporter()\n",
    "    \n",
    "test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.2867\t Test Acc:91.99%\n"
     ]
    }
   ],
   "source": [
    "template = \"Test Loss:{:.4f}\\t Test Acc:{:.2f}%\"\n",
    "print(template.format(test_loss.result(),\n",
    "                      test_acc.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
